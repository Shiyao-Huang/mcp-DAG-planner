"""
Version: v1.0.0
Author: AI Assistant + User
Date: 2024-12-20
Dependencies: pathlib, json, datetime
"""

"""
DAGæ•°æ®å­˜å‚¨ç®¡ç†å™¨

```mermaid
graph TD
    A[DAGDataStorage] --> B[save_dagä¿å­˜DAG]
    A --> C[load_dagåŠ è½½DAG]
    A --> D[list_dagsåˆ—å‡ºDAG]
    A --> E[delete_dagåˆ é™¤DAG]
    
    B --> B1[åˆ›å»ºç›®å½•ç»“æ„]
    B --> B2[å†™å…¥JSONæ–‡ä»¶]
    B --> B3[åˆ›å»ºå¤‡ä»½]
    
    C --> C1[éªŒè¯æ–‡ä»¶å­˜åœ¨]
    C --> C2[è¯»å–JSONæ•°æ®]
    C --> C3[æ•°æ®ååºåˆ—åŒ–]
    
    D --> D1[æ‰«æDAGç›®å½•]
    D --> D2[è·å–æ–‡ä»¶å…ƒä¿¡æ¯]
    D --> D3[è¿”å›DAGåˆ—è¡¨]
    
    E --> E1[åˆ é™¤ä¸»æ–‡ä»¶]
    E --> E2[æ¸…ç†å¤‡ä»½]
    E --> E3[æ›´æ–°ç´¢å¼•]
```

æœ¬æ–‡ä»¶å®ç°DAGæ•°æ®çš„æŒä¹…åŒ–å­˜å‚¨å’Œç®¡ç†åŠŸèƒ½ã€‚

æ ¸å¿ƒåŠŸèƒ½ï¼š
- save_dag: ä¿å­˜DAGæ•°æ®åˆ°JSONæ–‡ä»¶
- load_dag: ä»JSONæ–‡ä»¶åŠ è½½DAGæ•°æ®
- list_dags: åˆ—å‡ºæ‰€æœ‰ä¿å­˜çš„DAG
- delete_dag: åˆ é™¤æŒ‡å®šçš„DAG
- backup_dag: åˆ›å»ºDAGå¤‡ä»½
"""

import json
import os
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, List, Optional, Union
import shutil
import hashlib


class DAGDataStorage:
    """DAGæ•°æ®å­˜å‚¨ç®¡ç†å™¨"""
    
    def __init__(self, base_path: str = "dag_data"):
        """
        åˆå§‹åŒ–å­˜å‚¨ç®¡ç†å™¨
        
        Args:
            base_path: å­˜å‚¨åŸºç¡€è·¯å¾„ï¼Œå¯ä»¥æ˜¯ç›¸å¯¹è·¯å¾„æˆ–ç»å¯¹è·¯å¾„
        """
        from pathlib import Path
        
        # åˆ¤æ–­æ˜¯å¦ä¸ºç»å¯¹è·¯å¾„
        base_path_obj = Path(base_path)
        if base_path_obj.is_absolute():
            # å¦‚æœæ˜¯ç»å¯¹è·¯å¾„ï¼Œç›´æ¥ä½¿ç”¨
            self.base_path = base_path_obj
        else:
            # å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ï¼Œåœ¨å½“å‰å·¥ä½œç›®å½•ä¸‹åˆ›å»º
            current_working_dir = Path.cwd().resolve()
            self.base_path = current_working_dir / base_path
        
        self.dags_path = self.base_path / "dags"
        self.backups_path = self.base_path / "backups"
        self.temp_path = self.base_path / "temp"
        
        print(f"ğŸ” å½“å‰å·¥ä½œç›®å½•: {Path.cwd()}")
        print(f"ğŸ” DAGå­˜å‚¨åŸºç¡€è·¯å¾„: {self.base_path}")
        print(f"ğŸ” DAGæ–‡ä»¶è·¯å¾„: {self.dags_path}")
        print(f"ğŸ” å¤‡ä»½è·¯å¾„: {self.backups_path}")
        print(f"ğŸ” ä¸´æ—¶è·¯å¾„: {self.temp_path}")
        
        # åˆ›å»ºå¿…è¦çš„ç›®å½•
        self._ensure_directories()
    
    def _ensure_directories(self) -> None:
        """ç¡®ä¿æ‰€æœ‰å¿…è¦çš„ç›®å½•å­˜åœ¨"""
        directories = [self.base_path, self.dags_path, self.backups_path, self.temp_path]
        for directory in directories:
            directory.mkdir(parents=True, exist_ok=True)
    
    def _generate_file_hash(self, data: Dict[str, Any]) -> str:
        """ç”Ÿæˆæ•°æ®çš„å“ˆå¸Œå€¼ç”¨äºæ–‡ä»¶å‘½å"""
        data_str = json.dumps(data, sort_keys=True, ensure_ascii=False)
        return hashlib.md5(data_str.encode()).hexdigest()[:8]
    
    def save_dag(self, dag_data: Dict[str, Any], dag_id: Optional[str] = None) -> Dict[str, Any]:
        """
        ä¿å­˜DAGæ•°æ®åˆ°æ–‡ä»¶
        
        Args:
            dag_data: DAGæ•°æ®å­—å…¸
            dag_id: å¯é€‰çš„DAG IDï¼Œå¦‚æœä¸æä¾›å°†è‡ªåŠ¨ç”Ÿæˆ
            
        Returns:
            DictåŒ…å«ä¿å­˜ç»“æœä¿¡æ¯
        """
        try:
            print(f"ğŸ”¥ å¼€å§‹ä¿å­˜DAGæ•°æ®ï¼Œæ•°æ®å¤§å°: {len(str(dag_data))} å­—ç¬¦")
            print(f"ğŸ”¥ å­˜å‚¨åŸºç¡€è·¯å¾„: {self.base_path}")
            print(f"ğŸ”¥ DAGè·¯å¾„: {self.dags_path}")
            
            # æ·»åŠ æ—¶é—´æˆ³
            dag_data["timestamp"] = datetime.now().isoformat()
            
            # ç”Ÿæˆæ–‡ä»¶å
            if not dag_id:
                dag_id = self._generate_file_hash(dag_data)
            
            layer_type = dag_data.get("layer_type", "unknown")
            filename = f"{layer_type}_layer_{dag_id}.json"
            file_path = self.dags_path / filename
            
            print(f"ğŸ”¥ å‡†å¤‡å†™å…¥æ–‡ä»¶: {file_path}")
            
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            self.dags_path.mkdir(parents=True, exist_ok=True)
            
            # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œåˆ›å»ºå¤‡ä»½
            if file_path.exists():
                print(f"ğŸ”¥ æ–‡ä»¶å·²å­˜åœ¨ï¼Œåˆ›å»ºå¤‡ä»½")
                self._create_backup(file_path)
            
            # ä¿å­˜ä¸»æ–‡ä»¶
            print(f"ğŸ”¥ æ­£åœ¨å†™å…¥JSONæ•°æ®...")
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(dag_data, f, ensure_ascii=False, indent=2)
            
            # éªŒè¯æ–‡ä»¶æ˜¯å¦çœŸçš„è¢«åˆ›å»º
            if file_path.exists():
                file_size = file_path.stat().st_size
                print(f"ğŸ”¥ æ–‡ä»¶æˆåŠŸåˆ›å»º! å¤§å°: {file_size} å­—èŠ‚")
            else:
                print(f"ğŸ”¥ é”™è¯¯: æ–‡ä»¶æ²¡æœ‰è¢«åˆ›å»º!")
                return {
                    "success": False,
                    "error": "æ–‡ä»¶åˆ›å»ºå¤±è´¥",
                    "error_type": "file_creation_failed"
                }
            
            # è¿”å›ä¿å­˜ä¿¡æ¯
            result = {
                "success": True,
                "file_path": str(file_path),
                "filename": filename,
                "dag_id": dag_id,
                "size_bytes": file_path.stat().st_size,
                "backup_created": file_path.with_suffix('.backup.json').exists()
            }
            
            print(f"âœ… DAGæ•°æ®å·²ä¿å­˜åˆ°: {file_path}")
            return result
            
        except Exception as e:
            print(f"ğŸ”¥ ä¿å­˜è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            print(f"ğŸ”¥ é”™è¯¯ç±»å‹: {type(e).__name__}")
            import traceback
            print(f"ğŸ”¥ å †æ ˆè·Ÿè¸ª: {traceback.format_exc()}")
            
            error_result = {
                "success": False,
                "error": str(e),
                "error_type": "storage_error"
            }
            print(f"âŒ ä¿å­˜DAGæ•°æ®å¤±è´¥: {e}")
            return error_result
    
    def load_dag(self, filename: str) -> Dict[str, Any]:
        """
        ä»æ–‡ä»¶åŠ è½½DAGæ•°æ®
        
        Args:
            filename: è¦åŠ è½½çš„æ–‡ä»¶å
            
        Returns:
            DictåŒ…å«DAGæ•°æ®æˆ–é”™è¯¯ä¿¡æ¯
        """
        try:
            file_path = self.dags_path / filename
            
            if not file_path.exists():
                return {
                    "success": False,
                    "error": f"æ–‡ä»¶ä¸å­˜åœ¨: {filename}",
                    "error_type": "file_not_found"
                }
            
            with open(file_path, 'r', encoding='utf-8') as f:
                dag_data = json.load(f)
            
            result = {
                "success": True,
                "data": dag_data,
                "filename": filename,
                "file_path": str(file_path),
                "loaded_at": datetime.now().isoformat()
            }
            
            print(f"âœ… DAGæ•°æ®å·²ä»æ–‡ä»¶åŠ è½½: {file_path}")
            return result
            
        except Exception as e:
            error_result = {
                "success": False,
                "error": str(e),
                "error_type": "load_error"
            }
            print(f"âŒ åŠ è½½DAGæ•°æ®å¤±è´¥: {e}")
            return error_result
    
    def list_dags(self) -> Dict[str, Any]:
        """
        åˆ—å‡ºæ‰€æœ‰ä¿å­˜çš„DAGæ–‡ä»¶
        
        Returns:
            DictåŒ…å«DAGæ–‡ä»¶åˆ—è¡¨
        """
        try:
            dag_files = []
            
            for file_path in self.dags_path.glob("*.json"):
                if not file_path.name.endswith('.backup.json'):
                    stat = file_path.stat()
                    dag_files.append({
                        "filename": file_path.name,
                        "size_bytes": stat.st_size,
                        "modified_at": datetime.fromtimestamp(stat.st_mtime).isoformat(),
                        "created_at": datetime.fromtimestamp(stat.st_ctime).isoformat()
                    })
            
            # æŒ‰ä¿®æ”¹æ—¶é—´æ’åº
            dag_files.sort(key=lambda x: x["modified_at"], reverse=True)
            
            return {
                "success": True,
                "dags": dag_files,
                "total_count": len(dag_files),
                "scan_time": datetime.now().isoformat()
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "error_type": "list_error"
            }
    
    def delete_dag(self, filename: str) -> Dict[str, Any]:
        """
        åˆ é™¤æŒ‡å®šçš„DAGæ–‡ä»¶
        
        Args:
            filename: è¦åˆ é™¤çš„æ–‡ä»¶å
            
        Returns:
            DictåŒ…å«åˆ é™¤ç»“æœ
        """
        try:
            file_path = self.dags_path / filename
            backup_path = file_path.with_suffix('.backup.json')
            
            if not file_path.exists():
                return {
                    "success": False,
                    "error": f"æ–‡ä»¶ä¸å­˜åœ¨: {filename}",
                    "error_type": "file_not_found"
                }
            
            # åˆ é™¤ä¸»æ–‡ä»¶
            file_path.unlink()
            
            # åˆ é™¤å¤‡ä»½æ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            backup_deleted = False
            if backup_path.exists():
                backup_path.unlink()
                backup_deleted = True
            
            return {
                "success": True,
                "filename": filename,
                "backup_deleted": backup_deleted,
                "deleted_at": datetime.now().isoformat()
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "error_type": "delete_error"
            }
    
    def _create_backup(self, file_path: Path) -> bool:
        """
        åˆ›å»ºæ–‡ä»¶å¤‡ä»½
        
        Args:
            file_path: è¦å¤‡ä»½çš„æ–‡ä»¶è·¯å¾„
            
        Returns:
            bool: å¤‡ä»½æ˜¯å¦æˆåŠŸ
        """
        try:
            backup_path = file_path.with_suffix('.backup.json')
            shutil.copy2(file_path, backup_path)
            return True
        except Exception as e:
            print(f"âš ï¸ åˆ›å»ºå¤‡ä»½å¤±è´¥: {e}")
            return False
    
    def get_storage_stats(self) -> Dict[str, Any]:
        """
        è·å–å­˜å‚¨ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            DictåŒ…å«å­˜å‚¨ç»Ÿè®¡ä¿¡æ¯
        """
        try:
            dag_files = list(self.dags_path.glob("*.json"))
            backup_files = list(self.backups_path.glob("*.json"))
            temp_files = list(self.temp_path.glob("*"))
            
            total_size = sum(f.stat().st_size for f in dag_files)
            backup_size = sum(f.stat().st_size for f in backup_files)
            
            return {
                "success": True,
                "stats": {
                    "total_dags": len([f for f in dag_files if not f.name.endswith('.backup.json')]),
                    "backup_files": len(backup_files),
                    "temp_files": len(temp_files),
                    "total_size_bytes": total_size,
                    "backup_size_bytes": backup_size,
                    "storage_path": str(self.base_path)
                }
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "error_type": "stats_error"
            }


# å…¨å±€å­˜å‚¨å®ä¾‹
_storage_instance = None


def get_storage(project_path: str = None) -> DAGDataStorage:
    """è·å–å…¨å±€å­˜å‚¨å®ä¾‹ï¼Œä¼˜å…ˆä½¿ç”¨YAMLç¼“å­˜ä¸­çš„é¡¹ç›®è·¯å¾„"""
    global _storage_instance
    if _storage_instance is None:
        if project_path:
            # ä½¿ç”¨æŒ‡å®šçš„é¡¹ç›®è·¯å¾„
            edata_path = Path(project_path) / ".EDATA"
            _storage_instance = DAGDataStorage(str(edata_path))
        else:
            # ä¼˜å…ˆä»YAMLç¼“å­˜è·å–é¡¹ç›®è·¯å¾„
            try:
                from .path_cache import get_project_path_from_cache
                cached_project_path = get_project_path_from_cache()
                
                if cached_project_path:
                    edata_path = Path(cached_project_path) / ".EDATA"
                    print(f"ğŸ¯ ä»ç¼“å­˜è·å–é¡¹ç›®è·¯å¾„: {cached_project_path}")
                    _storage_instance = DAGDataStorage(str(edata_path))
                else:
                    # å¦‚æœç¼“å­˜ä¸­æ²¡æœ‰ï¼Œä½¿ç”¨fallbackæœºåˆ¶
                    current_dir = Path.cwd()
                    
                    possible_paths = [
                        current_dir / ".EDATA", 
                        current_dir.parent / ".EDATA",
                        Path("/Users/swmt/Desktop/hsy/å¤§æ¨¡å‹/MCP-some/.EDATA")  # é»˜è®¤é¡¹ç›®è·¯å¾„
                    ]
                    
                    edata_path = None
                    for path in possible_paths:
                        if path.exists() and (path / "config.json").exists():
                            edata_path = path
                            print(f"ğŸ” ä½¿ç”¨fallbackè·¯å¾„: {path.parent}")
                            break
                    
                    if edata_path:
                        _storage_instance = DAGDataStorage(str(edata_path))
                    else:
                        # æœ€ååˆ›å»ºåœ¨å½“å‰ç›®å½•ä¸‹
                        print("âš ï¸ æœªæ‰¾åˆ°æœ‰æ•ˆè·¯å¾„ï¼Œåœ¨å½“å‰ç›®å½•åˆ›å»º.EDATA")
                        _storage_instance = DAGDataStorage(".EDATA")
                        
            except Exception as e:
                print(f"âš ï¸ ç¼“å­˜è¯»å–å¤±è´¥ï¼Œä½¿ç”¨fallback: {e}")
                # å‘ç”Ÿé”™è¯¯æ—¶ä½¿ç”¨åŸæ¥çš„fallbackæœºåˆ¶
                current_dir = Path.cwd()
                
                possible_paths = [
                    current_dir / ".EDATA", 
                    current_dir.parent / ".EDATA",
                    Path("/Users/swmt/Desktop/hsy/å¤§æ¨¡å‹/MCP-some/.EDATA")
                ]
                
                edata_path = None
                for path in possible_paths:
                    if path.exists() and (path / "config.json").exists():
                        edata_path = path
                        break
                
                if edata_path:
                    _storage_instance = DAGDataStorage(str(edata_path))
                else:
                    _storage_instance = DAGDataStorage(".EDATA")
    
    return _storage_instance 